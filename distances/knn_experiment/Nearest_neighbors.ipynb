{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo:\n",
    "\n",
    "Write function that, given a reference set, finds the K (hyperparam) nearest neighbors in the 7d feature space and returns the average vote for those neighbors\n",
    "\n",
    "Cross validate on val sets\n",
    "\n",
    "\n",
    "\n",
    "Conditions\n",
    "\"Train\" on domain, eval on same domain (try on each of the 4)\n",
    "\"Train\" on n domains, eval on 1 (1 vs 1, 2 vs 1, 3 vs 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import csv\n",
    "from itertools import islice\n",
    "from functools import reduce\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Image\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tqdm import tqdm_notebook\n",
    "import torch\n",
    "from torchvision import models, transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: Votes are counted as [fake, real], not [incorrect, correct] !\n",
    "\n",
    "dataset_counts = defaultdict(int)\n",
    "img_counts = defaultdict(lambda : defaultdict(int))\n",
    "unique_imgs = defaultdict(set)\n",
    "img_votes = defaultdict(lambda: defaultdict(lambda: [0,0])) #no,yes tuples by dataset and image\n",
    "\n",
    "with open('../../all_gans_inf.csv') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in islice(reader, None):\n",
    "        img = row['img']        \n",
    "#         dataset_name = img[:img.index('/')]\n",
    "        split_name = img.split('/')\n",
    "        assert(len(split_name) == 2)\n",
    "        dataset_name, img_name = split_name\n",
    "        \n",
    "        vote_index = 1 if row['correctness'] == row['realness'] else 0\n",
    "        if dataset_name == 'began5000' and row['realness'] == 'True': print(row)\n",
    "\n",
    "        img_votes[dataset_name][img_name][vote_index] += 1\n",
    "        \n",
    "        dataset_counts[dataset_name] += 1\n",
    "        img_counts[dataset_name][img_name] += 1\n",
    "unique_imgs = {dataset: len(img_counts[dataset]) for dataset in img_counts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2233, 2397, 3103)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "progan_votes = img_votes['progan5000']\n",
    "began_votes = img_votes['began5000']\n",
    "stylegan_votes = img_votes['styleganceleba5000']\n",
    "len(progan_votes), len(began_votes), len(stylegan_votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "progan_filenames = torch.load('progan_filenames.pt', map_location=torch.device('cpu'))\n",
    "progan_filenames = [os.path.split(x)[-1] for x in progan_filenames]\n",
    "progan_distance_features = torch.load('progan_distance_features.pt', map_location=torch.device('cpu'))\n",
    "\n",
    "stylegan_filenames = torch.load('stylegan_filenames.pt', map_location=torch.device('cpu'))\n",
    "stylegan_filenames = [os.path.split(x)[-1] for x in stylegan_filenames]\n",
    "stylegan_distance_features = torch.load('stylegan_distance_features.pt', map_location=torch.device('cpu'))\n",
    "\n",
    "began_filenames = torch.load('began_filenames.pt', map_location=torch.device('cpu'))\n",
    "began_filenames = [os.path.split(x)[-1] for x in began_filenames]\n",
    "began_distance_features = torch.load('began_distance_features.pt', map_location=torch.device('cpu'))\n",
    "\n",
    "wgan_filenames = torch.load('wgan_filenames.pt', map_location=torch.device('cpu'))\n",
    "wgan_filenames = [os.path.split(x)[-1] for x in wgan_filenames]\n",
    "wgan_distance_features = torch.load('wgan_distance_features.pt', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../progan_train_set.txt') as f:\n",
    "    progan_train_files = [os.path.split(x.strip())[-1] for x in f.readlines()]\n",
    "#print(progan_train_files[:5])\n",
    "\n",
    "with open('../progan_val_set.txt') as f:\n",
    "    progan_val_files = [os.path.split(x.strip())[-1] for x in f.readlines()]\n",
    "#print(progan_val_files[:5])\n",
    "\n",
    "with open('../stylegan_train_set.txt') as f:\n",
    "    stylegan_train_files = [os.path.split(x.strip())[-1] for x in f.readlines()]\n",
    "#print(stylegan_train_files[:5])\n",
    "\n",
    "with open('../stylegan_val_set.txt') as f:\n",
    "    stylegan_val_files = [os.path.split(x.strip())[-1] for x in f.readlines()]\n",
    "#print(stylegan_val_files[:5])\n",
    "\n",
    "with open('../began_train_set.txt') as f:\n",
    "    began_train_files = [os.path.split(x.strip())[-1] for x in f.readlines()]\n",
    "#print(began_train_files[:5])\n",
    "\n",
    "with open('../began_val_set.txt') as f:\n",
    "    began_val_files = [os.path.split(x.strip())[-1] for x in f.readlines()]\n",
    "#print(began_val_files[:5])\n",
    "\n",
    "with open('../wgan_train_set.txt') as f:\n",
    "    wgan_train_files = [os.path.split(x.strip())[-1] for x in f.readlines()]\n",
    "#print(began_train_files[:5])\n",
    "\n",
    "with open('../wgan_val_set.txt') as f:\n",
    "    wgan_val_files = [os.path.split(x.strip())[-1] for x in f.readlines()]\n",
    "#print(began_val_files[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2233\n",
      "3103\n",
      "1966\n",
      "4251\n"
     ]
    }
   ],
   "source": [
    "progan_features_by_file = {progan_filenames[i] : progan_distance_features[i] for i in range(len(progan_filenames))}\n",
    "print(len(progan_features_by_file))\n",
    "\n",
    "stylegan_features_by_file = {stylegan_filenames[i] : stylegan_distance_features[i] for i in range(len(stylegan_filenames))}\n",
    "print(len(stylegan_features_by_file))\n",
    "\n",
    "began_features_by_file = {began_filenames[i] : began_distance_features[i] for i in range(len(began_filenames))}\n",
    "print(len(began_features_by_file))\n",
    "\n",
    "wgan_features_by_file = {wgan_filenames[i] : wgan_distance_features[i] for i in range(len(wgan_filenames))}\n",
    "print(len(wgan_features_by_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1787, 7)\n",
      "(2483, 7)\n",
      "(1574, 7)\n",
      "(3401, 7)\n"
     ]
    }
   ],
   "source": [
    "progan_train_feats = np.array([progan_features_by_file[x] for x in progan_train_files])\n",
    "print(progan_train_feats.shape)\n",
    "\n",
    "stylegan_train_feats = np.array([stylegan_features_by_file[x] for x in stylegan_train_files])\n",
    "print(stylegan_train_feats.shape)\n",
    "\n",
    "began_train_feats = np.array([began_features_by_file[x] for x in began_train_files])\n",
    "print(began_train_feats.shape)\n",
    "\n",
    "wgan_train_feats = np.array([wgan_features_by_file[x] for x in wgan_train_files])\n",
    "print(wgan_train_feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190 116 0.6209150326797386\n"
     ]
    }
   ],
   "source": [
    "correct_guesses = 0\n",
    "incorrect_guesses = 0\n",
    "\n",
    "K = 250\n",
    "\n",
    "for x in islice(progan_val_files, None):\n",
    "    #print(x)\n",
    "    feats = progan_features_by_file[x]\n",
    "    dists = np.linalg.norm(feats - progan_train_feats, axis=1)\n",
    "    #nn_index = np.argmin(dists)\n",
    "    #nn = progan_train_files[nn_index]\n",
    "    \n",
    "    kNN = sorted(enumerate(dists), key = lambda x: x[1])[:K]\n",
    "    kNN_votes = reduce(lambda x, y: [x[0] + y[0], x[1] + y[1]], [progan_votes[progan_train_files[z[0]]] for z in kNN])\n",
    "    \n",
    "    fake_votes, real_votes = kNN_votes\n",
    "    pred_real = real_votes >= fake_votes\n",
    "    \n",
    "    val_fake_votes, val_real_votes = progan_votes[x]\n",
    "    \n",
    "    if pred_real:\n",
    "        correct_guesses += val_real_votes\n",
    "        incorrect_guesses += val_fake_votes\n",
    "    else:\n",
    "        correct_guesses += val_fake_votes\n",
    "        incorrect_guesses += val_real_votes\n",
    "\n",
    "print(correct_guesses, incorrect_guesses, correct_guesses / (correct_guesses + incorrect_guesses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in islice(began_val_files,50):\n",
    "    #print(x)\n",
    "    feats = began_features_by_file[x]\n",
    "    dists = np.linalg.norm(feats - began_train_feats, axis=1)\n",
    "    nn_index = np.argmin(dists)\n",
    "    nn = began_train_files[nn_index]\n",
    "    #print(began_votes[nn])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1309, 0.36460143), (373, 0.40736032), (831, 0.47139472), (1171, 0.49929243), (828, 0.5257756)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4, 2]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kNN = sorted(enumerate(dists), key = lambda x: x[1])[:5]\n",
    "print(kNN)\n",
    "\n",
    "reduce(lambda x, y: [x[0] + y[0], x[1] + y[1]], [progan_votes[progan_train_files[x[0]]] for x in kNN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1309"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin(dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
